import type { Context } from "grammy";
import type { Agent } from "../agent.js";
import {
  GoogleGenerativeAI,
  type Part,
} from "@google/generative-ai";
import OpenAI from "openai";
import type { Config } from "../config.js";
import https from "node:https";
import http from "node:http";

// â”€â”€ Helper: Is OpenAI config? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function isOpenAIConfig(config: Config): boolean {
  return !!(config.modelApiBase?.includes("openai.com")) ||
    config.modelName.startsWith("gpt-") ||
    config.modelName.startsWith("o1") ||
    config.modelName.startsWith("o3") ||
    config.modelName.startsWith("o4");
}

// â”€â”€ Photo Handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function registerPhotoHandler(
  bot: { on: Function },
  agent: Agent,
  config: Config
): void {
  bot.on("message:photo", async (ctx: Context) => {
    const userName = ctx.from?.first_name || "User";
    console.log(`ğŸ“¸ ${userName}: sent a photo`);
    await ctx.replyWithChatAction("typing");

    try {
      const photos = ctx.message!.photo!;
      const bestPhoto = photos.at(-1)!;
      const file = await ctx.api.getFile(bestPhoto.file_id);
      const fileUrl = `https://api.telegram.org/file/bot${config.telegramBotToken}/${file.file_path}`;
      const imageBuffer = await downloadFile(fileUrl);
      const base64Image = imageBuffer.toString("base64");
      const caption = ctx.message!.caption || "";
      const prompt = caption
        ? `KullanÄ±cÄ± bu fotoÄŸrafÄ± ÅŸu mesajla gÃ¶nderdi: "${caption}". FotoÄŸrafÄ± analiz et ve yanÄ±tla.`
        : "Bu fotoÄŸrafÄ± analiz et. Ne gÃ¶rÃ¼yorsun? KÄ±sa ve Ã¶z aÃ§Ä±kla.";

      let response: string;

      if (isOpenAIConfig(config) && config.openaiApiKey) {
        // GPT-5.2 Vision
        const openai = new OpenAI({
          apiKey: config.openaiApiKey,
          baseURL: config.modelApiBase ?? undefined,
        });
        const result = await openai.chat.completions.create({
          model: config.modelName,
          messages: [{
            role: "user",
            content: [
              { type: "text", text: prompt },
              { type: "image_url", image_url: { url: `data:image/jpeg;base64,${base64Image}`, detail: "high" } },
            ],
          }],
        });
        response = result.choices[0]?.message?.content || "(No response)";
      } else {
        // Gemini Vision
        const genAI = new GoogleGenerativeAI(config.modelApiKey);
        const model = genAI.getGenerativeModel({ model: config.modelName });
        const imagePart: Part = { inlineData: { data: base64Image, mimeType: "image/jpeg" } };
        const result = await model.generateContent([prompt, imagePart]);
        response = result.response.text();
      }

      await sendSplitReply(ctx, response);
    } catch (error) {
      const errMsg = error instanceof Error ? error.message : String(error);
      console.error(`âŒ Photo analysis error: ${errMsg}`);
      await ctx.reply("âš ï¸ FotoÄŸraf analiz edilemedi. LÃ¼tfen tekrar deneyin.");
    }
  });
}

// â”€â”€ Document Handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const SUPPORTED_MIME_TYPES = [
  "application/pdf",
  "text/plain",
  "text/csv",
  "text/html",
  "text/markdown",
  "application/json",
  "image/jpeg",
  "image/png",
  "image/webp",
  "image/gif",
];

function isSupportedMime(mimeType: string): boolean {
  return SUPPORTED_MIME_TYPES.some((t) => mimeType.startsWith(t));
}

function isTextMime(mimeType: string): boolean {
  return mimeType.startsWith("text/") || mimeType === "application/json";
}

function isImageMime(mimeType: string): boolean {
  return mimeType.startsWith("image/");
}

export function registerDocumentHandler(
  bot: { on: Function },
  agent: Agent,
  config: Config
): void {
  bot.on("message:document", async (ctx: Context) => {
    const userName = ctx.from?.first_name || "User";
    const doc = ctx.message!.document!;
    const fileName = doc.file_name || "unknown";
    const mimeType = doc.mime_type || "application/octet-stream";

    console.log(`ğŸ“„ ${userName}: sent document "${fileName}" (${mimeType})`);

    if (doc.file_size && doc.file_size > 20 * 1024 * 1024) {
      await ctx.reply("âš ï¸ Dosya Ã§ok bÃ¼yÃ¼k (max 20MB). Daha kÃ¼Ã§Ã¼k bir dosya gÃ¶nderin.");
      return;
    }

    if (!isSupportedMime(mimeType)) {
      await ctx.reply(
        `âš ï¸ Bu dosya tÃ¼rÃ¼ desteklenmiyor: ${mimeType}\n` +
        `Desteklenen: PDF, TXT, CSV, JSON, resim dosyalarÄ±`
      );
      return;
    }

    await ctx.replyWithChatAction("typing");

    try {
      const file = await ctx.api.getFile(doc.file_id);
      const fileUrl = `https://api.telegram.org/file/bot${config.telegramBotToken}/${file.file_path}`;
      const fileBuffer = await downloadFile(fileUrl);
      const caption = ctx.message!.caption || "";
      const prompt = caption
        ? `KullanÄ±cÄ± "${fileName}" dosyasÄ±nÄ± ÅŸu mesajla gÃ¶nderdi: "${caption}". DosyayÄ± analiz et.`
        : `"${fileName}" dosyasÄ±nÄ± analiz et. Ä°Ã§eriÄŸini kÄ±saca Ã¶zetle.`;

      if (isTextMime(mimeType)) {
        // Text files: pass as message text to full agent (with tool support)
        const textContent = fileBuffer.toString("utf-8");
        const truncated = textContent.length > 30000
          ? textContent.substring(0, 30000) + "\n\n...[dosya kÄ±saltÄ±ldÄ±]"
          : textContent;

        const response = await agent.processMessage(
          `${prompt}\n\nDosya iÃ§eriÄŸi:\n\`\`\`\n${truncated}\n\`\`\``
        );
        await sendSplitReply(ctx, response);

      } else if (isImageMime(mimeType) && isOpenAIConfig(config) && config.openaiApiKey) {
        // Image documents via GPT Vision
        const openai = new OpenAI({
          apiKey: config.openaiApiKey,
          baseURL: config.modelApiBase ?? undefined,
        });
        const base64 = fileBuffer.toString("base64");
        const result = await openai.chat.completions.create({
          model: config.modelName,
          messages: [{
            role: "user",
            content: [
              { type: "text", text: prompt },
              { type: "image_url", image_url: { url: `data:${mimeType};base64,${base64}`, detail: "high" } },
            ],
          }],
        });
        await sendSplitReply(ctx, result.choices[0]?.message?.content || "(No response)");

      } else if (isImageMime(mimeType)) {
        // Image documents via Gemini Vision
        const genAI = new GoogleGenerativeAI(config.modelApiKey);
        const model = genAI.getGenerativeModel({ model: config.modelName });
        const filePart: Part = { inlineData: { data: fileBuffer.toString("base64"), mimeType } };
        const result = await model.generateContent([prompt, filePart]);
        await sendSplitReply(ctx, result.response.text());

      } else {
        // PDF and other binary documents â€” Gemini handles natively, GPT via base64
        if (isOpenAIConfig(config) && config.openaiApiKey && mimeType === "application/pdf") {
          // GPT-5.2 doesn't support native PDF â€” extract text via message
          await ctx.reply("ğŸ“„ PDF analizi yapÄ±lÄ±yor (metin Ã§Ä±karma)...");
          const response = await agent.processMessage(
            `${prompt}\n\n[PDF dosyasÄ± alÄ±ndÄ±: ${fileName}, ${Math.round((doc.file_size ?? 0) / 1024)}KB â€” ` +
            `DosyayÄ± analiz edemiyorum doÄŸrudan, ama iÃ§eriÄŸi metin olarak yapÄ±ÅŸtÄ±rabilirsin.]`
          );
          await sendSplitReply(ctx, response);
        } else {
          // Gemini native PDF support
          const genAI = new GoogleGenerativeAI(config.modelApiKey);
          const model = genAI.getGenerativeModel({ model: config.modelName });
          const filePart: Part = { inlineData: { data: fileBuffer.toString("base64"), mimeType } };
          const result = await model.generateContent([prompt, filePart]);
          await sendSplitReply(ctx, result.response.text());
        }
      }

    } catch (error) {
      const errMsg = error instanceof Error ? error.message : String(error);
      console.error(`âŒ Document analysis error: ${errMsg}`);
      await ctx.reply("âš ï¸ Dosya analiz edilemedi. LÃ¼tfen tekrar deneyin.");
    }
  });
}

// â”€â”€ Video Handler (NEW â€” GPT-5.2 only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function registerVideoHandler(
  bot: { on: Function },
  agent: Agent,
  config: Config
): void {
  bot.on("message:video", async (ctx: Context) => {
    const userName = ctx.from?.first_name || "User";
    const video = ctx.message!.video!;
    console.log(`ğŸ¥ ${userName}: sent a video (${Math.round((video.file_size ?? 0) / 1024)}KB, ${video.duration}s)`);

    // Size check â€” Telegram bots can only download up to 20MB
    if (video.file_size && video.file_size > 20 * 1024 * 1024) {
      await ctx.reply("âš ï¸ Video Ã§ok bÃ¼yÃ¼k (max 20MB). Daha kÄ±sa/kÃ¼Ã§Ã¼k bir video gÃ¶nderin.");
      return;
    }

    // GPT-5.2 Vision supports video frames â€” Gemini also supports video
    await ctx.replyWithChatAction("upload_video");

    try {
      const file = await ctx.api.getFile(video.file_id);
      const fileUrl = `https://api.telegram.org/file/bot${config.telegramBotToken}/${file.file_path}`;
      const videoBuffer = await downloadFile(fileUrl);
      const caption = ctx.message!.caption || "";
      const prompt = caption
        ? `KullanÄ±cÄ± bu videoyu ÅŸu mesajla gÃ¶nderdi: "${caption}". Videoyu analiz et.`
        : "Bu videoyu analiz et. Ne oluyor? KÄ±saca aÃ§Ä±kla.";

      let response: string;

      if (isOpenAIConfig(config) && config.openaiApiKey) {
        // GPT-5.2: Video as base64 (mp4)
        const openai = new OpenAI({
          apiKey: config.openaiApiKey,
          baseURL: config.modelApiBase ?? undefined,
        });
        const base64Video = videoBuffer.toString("base64");
        const mimeType = "video/mp4";
        const result = await openai.chat.completions.create({
          model: config.modelName,
          messages: [{
            role: "user",
            content: [
              { type: "text", text: prompt },
              // GPT-5.2 video input
              { type: "image_url", image_url: { url: `data:${mimeType};base64,${base64Video}` } },
            ],
          }],
        });
        response = result.choices[0]?.message?.content || "(No response)";
      } else {
        // Gemini: Native video support
        const genAI = new GoogleGenerativeAI(config.modelApiKey);
        const model = genAI.getGenerativeModel({ model: config.modelName });
        const videoPart: Part = {
          inlineData: { data: videoBuffer.toString("base64"), mimeType: "video/mp4" },
        };
        const result = await model.generateContent([prompt, videoPart]);
        response = result.response.text();
      }

      await sendSplitReply(ctx, response);
    } catch (error) {
      const errMsg = error instanceof Error ? error.message : String(error);
      console.error(`âŒ Video analysis error: ${errMsg}`);
      await ctx.reply("âš ï¸ Video analiz edilemedi. LÃ¼tfen tekrar deneyin.");
    }
  });
}

// â”€â”€ Shared Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function sendSplitReply(ctx: Context, response: string): Promise<void> {
  if (response.length <= 4096) {
    await ctx.reply(response);
    return;
  }
  for (let i = 0; i < response.length; i += 4096) {
    await ctx.reply(response.substring(i, i + 4096));
  }
}

function downloadFile(url: string): Promise<Buffer> {
  return new Promise((resolve, reject) => {
    const client = url.startsWith("https") ? https : http;
    client.get(url, (res) => {
      const chunks: Buffer[] = [];
      res.on("data", (chunk: Buffer) => chunks.push(chunk));
      res.on("end", () => resolve(Buffer.concat(chunks)));
      res.on("error", reject);
    }).on("error", reject);
  });
}
